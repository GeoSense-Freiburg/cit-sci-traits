{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1.0: Train trait models with Autogluon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "import dask.dataframe as dd\n",
    "from dask.distributed import Client\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from src.conf.conf import get_config\n",
    "from src.conf.environment import log\n",
    "from src.utils.log_utils import get_loggers_starting_with\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "cfg = get_config()\n",
    "\n",
    "train_dir = Path(cfg.train.dir) / cfg.PFT / cfg.model_res / cfg.datasets.Y.use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Client(dashboard_address=cfg.dask_dashboard, n_workers=80):\n",
    "    dask_loggers = get_loggers_starting_with(\"distributed\")\n",
    "    for logger_name in dask_loggers:\n",
    "        logging.getLogger(logger_name).setLevel(\"WARNING\")\n",
    "\n",
    "    feats = (\n",
    "        dd.read_parquet(train_dir / cfg.train.features)\n",
    "        .drop(columns=[\"x\", \"y\"])\n",
    "    )\n",
    "    Y_cols = feats.columns[feats.columns.str.startswith(\"X\")].to_list()\n",
    "    X_cols = feats.columns[~feats.columns.str.startswith(\"X\")].to_list()\n",
    "\n",
    "    # Select all X_cols and first entry of Y_cols from feats\n",
    "    Xy = feats[X_cols + Y_cols[:1]].compute().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add CV fold IDs to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CV splits\n",
    "with open(train_dir / cfg.train.cv_splits.dir / f\"{Y_cols[0]}.pkl\", \"rb\") as f:\n",
    "    cv_splits = pickle.load(f)\n",
    "\n",
    "# Each split is a tuple of (train_idx, valid_idx). Assign the split number to each set\n",
    "# of valid_idx in Xy\n",
    "for i, (_, valid_idx) in enumerate(cv_splits):\n",
    "    Xy.loc[valid_idx, \"split\"] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train with Autogluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly sample 90% of the data for training\n",
    "train_idx = Xy.sample(frac=0.9, random_state=42).index\n",
    "test_idx = Xy.index.difference(train_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TabularDataset(Xy.loc[train_idx]).sample(\n",
    "    frac=0.01, random_state=cfg.random_seed\n",
    ")\n",
    "test_data = TabularDataset(Xy.loc[test_idx].drop(columns=[\"split\"])).sample(\n",
    "    frac=0.01, random_state=cfg.random_seed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"NN_TORCH\": {},\n",
    "    \"GBM\": [\n",
    "        {\"extra_trees\": True, \"ag_args\": {\"name_suffix\": \"XT\"}},\n",
    "        {},\n",
    "        \"GBMLarge\",\n",
    "    ],\n",
    "    \"CAT\": {},\n",
    "    \"XGB\": {},\n",
    "    \"FASTAI\": {},\n",
    "    \"RF\": [\n",
    "        {\n",
    "            \"criterion\": \"gini\",\n",
    "            \"ag_args\": {\n",
    "                \"name_suffix\": \"Gini\",\n",
    "                \"problem_types\": [\"binary\", \"multiclass\"],\n",
    "            },\n",
    "        },\n",
    "        {\n",
    "            \"criterion\": \"entropy\",\n",
    "            \"ag_args\": {\n",
    "                \"name_suffix\": \"Entr\",\n",
    "                \"problem_types\": [\"binary\", \"multiclass\"],\n",
    "            },\n",
    "        },\n",
    "        {\n",
    "            \"criterion\": \"squared_error\",\n",
    "            \"ag_args\": {\"name_suffix\": \"MSE\", \"problem_types\": [\"regression\"]},\n",
    "        },\n",
    "    ],\n",
    "    \"XT\": [\n",
    "        {\n",
    "            \"criterion\": \"gini\",\n",
    "            \"ag_args\": {\n",
    "                \"name_suffix\": \"Gini\",\n",
    "                \"problem_types\": [\"binary\", \"multiclass\"],\n",
    "            },\n",
    "        },\n",
    "        {\n",
    "            \"criterion\": \"entropy\",\n",
    "            \"ag_args\": {\n",
    "                \"name_suffix\": \"Entr\",\n",
    "                \"problem_types\": [\"binary\", \"multiclass\"],\n",
    "            },\n",
    "        },\n",
    "        {\n",
    "            \"criterion\": \"squared_error\",\n",
    "            \"ag_args\": {\"name_suffix\": \"MSE\", \"problem_types\": [\"regression\"]},\n",
    "        },\n",
    "    ],\n",
    "    \"KNN\": [\n",
    "        {\"weights\": \"uniform\", \"ag_args\": {\"name_suffix\": \"Unif\"}, \"n_jobs\": 16},\n",
    "        {\"weights\": \"distance\", \"ag_args\": {\"name_suffix\": \"Dist\"}, \"n_jobs\": 16},\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20240521_141509\"\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Values in column 'split' used as split folds instead of being automatically set. Bagged models will have 10 splits.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20240521_141509\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.11.9\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #117-Ubuntu SMP Fri Apr 26 12:26:49 UTC 2024\n",
      "CPU Count:          128\n",
      "Memory Avail:       741.06 GB / 755.20 GB (98.1%)\n",
      "Disk Space Avail:   12466.45 GB / 13100.23 GB (95.2%)\n",
      "===================================================\n",
      "Train Data Rows:    43450\n",
      "Train Data Columns: 151\n",
      "Label Column:       X4_mean\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (0.949698103, 0.171652033, 0.4852, 0.12236)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    758849.39 MB\n",
      "\tTrain Data (Original)  Memory Usage: 12.60 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) :   6 | ['wc2.1_30s_bio_1', 'wc2.1_30s_bio_12', 'wc2.1_30s_bio_13-14', 'wc2.1_30s_bio_15', 'wc2.1_30s_bio_4', ...]\n",
      "\t\t('int', [])   : 144 | ['ETH_GlobalCanopyHeightSD_2020_v1', 'ETH_GlobalCanopyHeight_2020_v1', 'sur_refl_b01_2001-2024_m10_mean', 'sur_refl_b01_2001-2024_m11_mean', 'sur_refl_b01_2001-2024_m12_mean', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) :   6 | ['wc2.1_30s_bio_1', 'wc2.1_30s_bio_12', 'wc2.1_30s_bio_13-14', 'wc2.1_30s_bio_15', 'wc2.1_30s_bio_4', ...]\n",
      "\t\t('int', [])   : 144 | ['ETH_GlobalCanopyHeightSD_2020_v1', 'ETH_GlobalCanopyHeight_2020_v1', 'sur_refl_b01_2001-2024_m10_mean', 'sur_refl_b01_2001-2024_m11_mean', 'sur_refl_b01_2001-2024_m12_mean', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t150 features in original data used to generate 150 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 12.60 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.16s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Excluded models: ['KNN'] (Specified by `excluded_model_types`)\n",
      "Fitting 9 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ...\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (9.0 workers, per: cpus=14, gpus=0, memory=0.01%)\n",
      "\t-0.1085\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.2s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (9.0 workers, per: cpus=14, gpus=0, memory=0.01%)\n",
      "\t-0.1086\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.03s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ...\n",
      "\tForcing `use_child_oof=False` because `groups` is specified\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (9.0 workers, per: cpus=14, gpus=0, memory=0.01%)\n",
      "\t-0.1091\t = Validation score   (-root_mean_squared_error)\n",
      "\t175.32s\t = Training   runtime\n",
      "\t15.76s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ...\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (8.0 workers, per: cpus=16, gpus=0, memory=0.02%)\n",
      "\t-0.1086\t = Validation score   (-root_mean_squared_error)\n",
      "\t12.0s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ...\n",
      "\tForcing `use_child_oof=False` because `groups` is specified\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (9.0 workers, per: cpus=14, gpus=0, memory=0.01%)\n",
      "\t-0.109\t = Validation score   (-root_mean_squared_error)\n",
      "\t37.56s\t = Training   runtime\n",
      "\t1.47s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ...\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (8.0 workers, per: cpus=16, gpus=0, memory=0.02%)\n",
      "\t-0.1084\t = Validation score   (-root_mean_squared_error)\n",
      "\t55.89s\t = Training   runtime\n",
      "\t0.39s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ...\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (8.0 workers, per: cpus=16, gpus=0, memory=0.02%)\n",
      "\t-0.1089\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.77s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ...\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=32, gpus=0, memory=0.01%)\n",
      "\t-0.1087\t = Validation score   (-root_mean_squared_error)\n",
      "\t83.93s\t = Training   runtime\n",
      "\t1.02s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ...\n",
      "\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (9.0 workers, per: cpus=14, gpus=0, memory=0.03%)\n",
      "\t-0.1087\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.45s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'NeuralNetFastAI_BAG_L1': 0.364, 'NeuralNetTorch_BAG_L1': 0.273, 'LightGBM_BAG_L1': 0.136, 'LightGBMLarge_BAG_L1': 0.091, 'RandomForestMSE_BAG_L1': 0.045, 'CatBoost_BAG_L1': 0.045, 'ExtraTreesMSE_BAG_L1': 0.045}\n",
      "\t-0.1079\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 394.6s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240521_141509\")\n"
     ]
    }
   ],
   "source": [
    "predictor = TabularPredictor(label=Y_cols[0], groups=\"split\").fit(\n",
    "    train_data, num_bag_folds=10, excluded_model_types=[\"KNN\"], num_gpus=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>-0.107900</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>18.821038</td>\n",
       "      <td>373.204322</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>0.025472</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NeuralNetFastAI_BAG_L1</td>\n",
       "      <td>-0.108403</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.393623</td>\n",
       "      <td>55.885975</td>\n",
       "      <td>0.393623</td>\n",
       "      <td>55.885975</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LightGBMXT_BAG_L1</td>\n",
       "      <td>-0.108462</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.044333</td>\n",
       "      <td>3.201824</td>\n",
       "      <td>0.044333</td>\n",
       "      <td>3.201824</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CatBoost_BAG_L1</td>\n",
       "      <td>-0.108561</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.074980</td>\n",
       "      <td>11.999588</td>\n",
       "      <td>0.074980</td>\n",
       "      <td>11.999588</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LightGBM_BAG_L1</td>\n",
       "      <td>-0.108596</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.041386</td>\n",
       "      <td>3.025867</td>\n",
       "      <td>0.041386</td>\n",
       "      <td>3.025867</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NeuralNetTorch_BAG_L1</td>\n",
       "      <td>-0.108671</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>1.016577</td>\n",
       "      <td>83.932865</td>\n",
       "      <td>1.016577</td>\n",
       "      <td>83.932865</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LightGBMLarge_BAG_L1</td>\n",
       "      <td>-0.108709</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.057727</td>\n",
       "      <td>5.448931</td>\n",
       "      <td>0.057727</td>\n",
       "      <td>5.448931</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGBoost_BAG_L1</td>\n",
       "      <td>-0.108857</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.251911</td>\n",
       "      <td>3.766204</td>\n",
       "      <td>0.251911</td>\n",
       "      <td>3.766204</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ExtraTreesMSE_BAG_L1</td>\n",
       "      <td>-0.108963</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>1.472878</td>\n",
       "      <td>37.564896</td>\n",
       "      <td>1.472878</td>\n",
       "      <td>37.564896</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RandomForestMSE_BAG_L1</td>\n",
       "      <td>-0.109122</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>15.763465</td>\n",
       "      <td>175.320727</td>\n",
       "      <td>15.763465</td>\n",
       "      <td>175.320727</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model  score_val              eval_metric  pred_time_val  \\\n",
       "0     WeightedEnsemble_L2  -0.107900  root_mean_squared_error      18.821038   \n",
       "1  NeuralNetFastAI_BAG_L1  -0.108403  root_mean_squared_error       0.393623   \n",
       "2       LightGBMXT_BAG_L1  -0.108462  root_mean_squared_error       0.044333   \n",
       "3         CatBoost_BAG_L1  -0.108561  root_mean_squared_error       0.074980   \n",
       "4         LightGBM_BAG_L1  -0.108596  root_mean_squared_error       0.041386   \n",
       "5   NeuralNetTorch_BAG_L1  -0.108671  root_mean_squared_error       1.016577   \n",
       "6    LightGBMLarge_BAG_L1  -0.108709  root_mean_squared_error       0.057727   \n",
       "7          XGBoost_BAG_L1  -0.108857  root_mean_squared_error       0.251911   \n",
       "8    ExtraTreesMSE_BAG_L1  -0.108963  root_mean_squared_error       1.472878   \n",
       "9  RandomForestMSE_BAG_L1  -0.109122  root_mean_squared_error      15.763465   \n",
       "\n",
       "     fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  \\\n",
       "0  373.204322                0.000403           0.025472            2   \n",
       "1   55.885975                0.393623          55.885975            1   \n",
       "2    3.201824                0.044333           3.201824            1   \n",
       "3   11.999588                0.074980          11.999588            1   \n",
       "4    3.025867                0.041386           3.025867            1   \n",
       "5   83.932865                1.016577          83.932865            1   \n",
       "6    5.448931                0.057727           5.448931            1   \n",
       "7    3.766204                0.251911           3.766204            1   \n",
       "8   37.564896                1.472878          37.564896            1   \n",
       "9  175.320727               15.763465         175.320727            1   \n",
       "\n",
       "   can_infer  fit_order  \n",
       "0       True         10  \n",
       "1       True          6  \n",
       "2       True          1  \n",
       "3       True          4  \n",
       "4       True          2  \n",
       "5       True          8  \n",
       "6       True          9  \n",
       "7       True          7  \n",
       "8       True          5  \n",
       "9       True          3  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = test_data[Y_cols[0]]\n",
    "y_pred = predictor.predict(test_data.drop(columns=[Y_cols[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'root_mean_squared_error': -0.10883326581256995,\n",
       " 'mean_squared_error': -0.01184467974742951,\n",
       " 'mean_absolute_error': -0.08415142601027989,\n",
       " 'r2': 0.23889501824464554,\n",
       " 'pearsonr': 0.49034440832120874,\n",
       " 'median_absolute_error': -0.06702506434064356}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance = predictor.evaluate_predictions(y_true, y_pred)\n",
    "performance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "traits",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
