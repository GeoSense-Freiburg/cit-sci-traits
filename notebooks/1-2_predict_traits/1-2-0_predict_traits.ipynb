{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2.0: Predict final trait maps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After employing spatial K-fold cross-validation (SKCV) during initial model training and evaluating ensemble model performance using a held-out test set of data, we are able to identify the best model for each trait and train a final model on all available data to produce global trait maps.\n",
    "\n",
    "This will entail:\n",
    "\n",
    "1. Selecting the best model based on the SKCV results\n",
    "2. Loading all available predictor and trait data\n",
    "3. Fitting the model on the full data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import dask.dataframe as dd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "from dask.distributed import Client\n",
    "\n",
    "from src.conf.conf import get_config\n",
    "from src.conf.environment import log\n",
    "from src.utils.dataset_utils import (\n",
    "    compute_partitions,\n",
    "    eo_ds_to_ddf,\n",
    "    get_eo_fns_list,\n",
    "    load_rasters_parallel,\n",
    "    map_da_dtypes,\n",
    ")\n",
    "\n",
    "cfg = get_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_d = Path(cfg.models.dir) / cfg.PFT / cfg.model_res / cfg.datasets.Y.use / cfg.train.arch\n",
    "model_dir = models_d / \"X11_mean/high_20240524_234626\"\n",
    "predictor = TabularPredictor.load(str(model_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the predictor data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing partitions:  12%|█▏        | 10/81 [07:12<51:10, 43.25s/it]\n",
      "/home/dl1070/micromamba/envs/traits_311/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3577: PerformanceWarning: Reshaping is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array.reshape(shape)\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array.reshape(shape)Explicitly passing ``limit`` to ``reshape`` will also silence this warning\n",
      "    >>> array.reshape(shape, limit='128 MiB')\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/home/dl1070/micromamba/envs/traits_311/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3577: PerformanceWarning: Reshaping is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array.reshape(shape)\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array.reshape(shape)Explicitly passing ``limit`` to ``reshape`` will also silence this warning\n",
      "    >>> array.reshape(shape, limit='128 MiB')\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "Computing partitions: 100%|██████████| 25/25 [16:00<00:00, 38.43s/it]\n"
     ]
    }
   ],
   "source": [
    "N_CHUNKS: int = 5\n",
    "\n",
    "with Client(dashboard_address=cfg.dask_dashboard, memory_limit=\"80GB\"):\n",
    "    eo_fns = get_eo_fns_list(stage=\"interim\")\n",
    "    dtypes = map_da_dtypes(eo_fns, dask=True, nchunks=N_CHUNKS)\n",
    "    ds = load_rasters_parallel(eo_fns, nchunks=N_CHUNKS)\n",
    "    ddf = eo_ds_to_ddf(ds, dtypes, sample=0.01)\n",
    "    df = compute_partitions(ddf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = predictor.predict(df.drop(columns=[\"x\", \"y\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6302212     16.507893\n",
       "4322335     17.485106\n",
       "11540528    17.740084\n",
       "3782221     17.224155\n",
       "4916370     16.720385\n",
       "Name: X11_mean, dtype: float32"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
