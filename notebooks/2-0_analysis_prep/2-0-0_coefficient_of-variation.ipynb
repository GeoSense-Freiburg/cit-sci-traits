{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0.0: Coefficient of Variation from cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can measure model performance using several metrics. To assess model reliability in terms of the reference data, we can calculate average $RMSE$ and $R^2$ values across all folds. To provide further indication of model robustness, however, we can also calculate the pixel-wise coefficient of variation (CoV), or the ratio of the standard deviation  to the mean  across all folds, defined as:\n",
    "\n",
    "$$CoV = \\frac{\\sigma}{\\mu}$$\n",
    "\n",
    "This, paired with Meyer and Pebesma's Area of Applicability (2022), can give us a better idea of where our extrapolated trait maps are more or less reliable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from autogluon.tabular import TabularPredictor\n",
    "from tqdm import trange\n",
    "\n",
    "from src.conf.conf import get_config\n",
    "from src.conf.environment import log\n",
    "from src.utils.autogluon_utils import get_best_model_ag\n",
    "\n",
    "cfg = get_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load CV models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get best base predictor\n",
    "\n",
    "First we load the AutoGluon `TabularPredictor` in order to retrieve the individual models from each cross-validation fold. But there's a catch: to get the best performance at inference time, our final models are actually ensemble models which don't contain sub-models for each CV fold. Instead, we'll need to identify the best-performing base model from the ensemble and generate trait predictions from each of its CV fold sub-models. This should then provide a fairly conservative CoV which the ensemble model should actually outperform slightly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = TabularPredictor.load(\n",
    "    \"models/Shrub_Tree_Grass/001/splot_gbif/autogluon/X11_mean/good_20240607_220933\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>-6.585418</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>579.164635</td>\n",
       "      <td>6507.011832</td>\n",
       "      <td>0.031631</td>\n",
       "      <td>0.452263</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WeightedEnsemble_L3</td>\n",
       "      <td>-6.585418</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>579.164829</td>\n",
       "      <td>6507.021219</td>\n",
       "      <td>0.031826</td>\n",
       "      <td>0.461649</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LightGBMXT_BAG_L1</td>\n",
       "      <td>-6.587197</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>480.394939</td>\n",
       "      <td>2224.356663</td>\n",
       "      <td>480.394939</td>\n",
       "      <td>2224.356663</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBM_BAG_L1</td>\n",
       "      <td>-6.598851</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>93.548172</td>\n",
       "      <td>725.426548</td>\n",
       "      <td>93.548172</td>\n",
       "      <td>725.426548</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ExtraTreesMSE_BAG_L1</td>\n",
       "      <td>-6.626949</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>5.189893</td>\n",
       "      <td>3556.776358</td>\n",
       "      <td>5.189893</td>\n",
       "      <td>3556.776358</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CatBoost_BAG_L1</td>\n",
       "      <td>-6.687462</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.478468</td>\n",
       "      <td>128.842230</td>\n",
       "      <td>0.478468</td>\n",
       "      <td>128.842230</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>WeightedEnsemble_L3_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1110.229789</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.461649</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>WeightedEnsemble_L2_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1110.220403</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.452263</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LightGBM_BAG_L1_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>NaN</td>\n",
       "      <td>138.430075</td>\n",
       "      <td>NaN</td>\n",
       "      <td>138.430075</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LightGBMXT_BAG_L1_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>NaN</td>\n",
       "      <td>574.082538</td>\n",
       "      <td>NaN</td>\n",
       "      <td>574.082538</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ExtraTreesMSE_BAG_L1_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>NaN</td>\n",
       "      <td>397.255527</td>\n",
       "      <td>NaN</td>\n",
       "      <td>397.255527</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CatBoost_BAG_L1_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.078692</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.078692</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        model  score_val              eval_metric  \\\n",
       "0         WeightedEnsemble_L2  -6.585418  root_mean_squared_error   \n",
       "1         WeightedEnsemble_L3  -6.585418  root_mean_squared_error   \n",
       "2           LightGBMXT_BAG_L1  -6.587197  root_mean_squared_error   \n",
       "3             LightGBM_BAG_L1  -6.598851  root_mean_squared_error   \n",
       "4        ExtraTreesMSE_BAG_L1  -6.626949  root_mean_squared_error   \n",
       "5             CatBoost_BAG_L1  -6.687462  root_mean_squared_error   \n",
       "6    WeightedEnsemble_L3_FULL        NaN  root_mean_squared_error   \n",
       "7    WeightedEnsemble_L2_FULL        NaN  root_mean_squared_error   \n",
       "8        LightGBM_BAG_L1_FULL        NaN  root_mean_squared_error   \n",
       "9      LightGBMXT_BAG_L1_FULL        NaN  root_mean_squared_error   \n",
       "10  ExtraTreesMSE_BAG_L1_FULL        NaN  root_mean_squared_error   \n",
       "11       CatBoost_BAG_L1_FULL        NaN  root_mean_squared_error   \n",
       "\n",
       "    pred_time_val     fit_time  pred_time_val_marginal  fit_time_marginal  \\\n",
       "0      579.164635  6507.011832                0.031631           0.452263   \n",
       "1      579.164829  6507.021219                0.031826           0.461649   \n",
       "2      480.394939  2224.356663              480.394939        2224.356663   \n",
       "3       93.548172   725.426548               93.548172         725.426548   \n",
       "4        5.189893  3556.776358                5.189893        3556.776358   \n",
       "5        0.478468   128.842230                0.478468         128.842230   \n",
       "6             NaN  1110.229789                     NaN           0.461649   \n",
       "7             NaN  1110.220403                     NaN           0.452263   \n",
       "8             NaN   138.430075                     NaN         138.430075   \n",
       "9             NaN   574.082538                     NaN         574.082538   \n",
       "10            NaN   397.255527                     NaN         397.255527   \n",
       "11            NaN    19.078692                     NaN          19.078692   \n",
       "\n",
       "    stack_level  can_infer  fit_order  \n",
       "0             2       True          5  \n",
       "1             3       True          6  \n",
       "2             1       True          1  \n",
       "3             1       True          2  \n",
       "4             1       True          4  \n",
       "5             1       True          3  \n",
       "6             3       True         12  \n",
       "7             2       True         11  \n",
       "8             1       True          8  \n",
       "9             1       True          7  \n",
       "10            1       True         10  \n",
       "11            1       True          9  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the best predictor that is not an ensemble model (i.e. `stack_level == 1`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = (\n",
    "    predictor.leaderboard(refit_full=False)\n",
    "    .pipe(lambda df: df[df[\"stack_level\"] == 1])\n",
    "    .pipe(lambda df: df.loc[df[\"score_val\"].idxmax()])\n",
    "    .model\n",
    ")\n",
    "\n",
    "cv_models_dir = Path(predictor.path, \"models\", str(best_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load inference data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_fn: Path = (\n",
    "    Path(cfg.train.dir)\n",
    "    / cfg.eo_data.predict.dir\n",
    "    / cfg.model_res\n",
    "    / cfg.eo_data.predict.filename\n",
    ")\n",
    "\n",
    "data = pd.read_parquet(predict_fn)\n",
    "xy = data[[\"x\", \"y\"]]\n",
    "data = data.drop(columns=[\"x\", \"y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-21 11:03:00 CEST - src.conf.environment - INFO - Predicting in batches...\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]2024-06-21 11:03:00 CEST - src.conf.environment - INFO - Predicting with S1F4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-21 11:14:58 CEST - src.conf.environment - INFO - Predicting with S1F8\n",
      "2024-06-21 11:27:12 CEST - src.conf.environment - INFO - Predicting with S1F5\n",
      "2024-06-21 11:38:07 CEST - src.conf.environment - INFO - Predicting with S1F10\n",
      "2024-06-21 11:50:36 CEST - src.conf.environment - INFO - Predicting with S1F2\n",
      "2024-06-21 12:02:55 CEST - src.conf.environment - INFO - Predicting with S1F1\n",
      "2024-06-21 12:13:22 CEST - src.conf.environment - INFO - Predicting with S1F3\n",
      "2024-06-21 12:26:26 CEST - src.conf.environment - INFO - Predicting with S1F6\n",
      "2024-06-21 12:36:03 CEST - src.conf.environment - INFO - Predicting with S1F7\n",
      "2024-06-21 12:49:13 CEST - src.conf.environment - INFO - Predicting with S1F9\n",
      "2024-06-21 13:02:13 CEST - src.conf.environment - INFO - Calculating coefficient of variation for batch 0...\n",
      "  0%|          | 0/1 [1:59:12<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot concatenate object of type '<class 'numpy.ndarray'>'; only Series and DataFrame objs are valid",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 24\u001b[0m\n\u001b[1;32m     22\u001b[0m     log\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalculating coefficient of variation for batch \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m, i)\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;66;03m# Calculate coefficient of variation across all submodel predictions\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m     batch_cov \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_predictions\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mstd(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m/\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(\n\u001b[1;32m     25\u001b[0m         batch_predictions\n\u001b[1;32m     26\u001b[0m     )\u001b[38;5;241m.\u001b[39mmean(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     27\u001b[0m     covs\u001b[38;5;241m.\u001b[39mappend(batch_cov)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Concatenate all batch predictions\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/traits-py311/lib/python3.11/site-packages/pandas/core/reshape/concat.py:382\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    380\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 382\u001b[0m op \u001b[38;5;241m=\u001b[39m \u001b[43m_Concatenator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[0;32m~/miniforge3/envs/traits-py311/lib/python3.11/site-packages/pandas/core/reshape/concat.py:448\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    445\u001b[0m objs, keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clean_keys_and_objs(objs, keys)\n\u001b[1;32m    447\u001b[0m \u001b[38;5;66;03m# figure out what our result ndim is going to be\u001b[39;00m\n\u001b[0;32m--> 448\u001b[0m ndims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_ndims\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    449\u001b[0m sample, objs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sample_object(objs, ndims, keys, names, levels)\n\u001b[1;32m    451\u001b[0m \u001b[38;5;66;03m# Standardize axis parameter to int\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/traits-py311/lib/python3.11/site-packages/pandas/core/reshape/concat.py:489\u001b[0m, in \u001b[0;36m_Concatenator._get_ndims\u001b[0;34m(self, objs)\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, (ABCSeries, ABCDataFrame)):\n\u001b[1;32m    485\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    486\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot concatenate object of type \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(obj)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m; \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    487\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124monly Series and DataFrame objs are valid\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    488\u001b[0m         )\n\u001b[0;32m--> 489\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m    491\u001b[0m     ndims\u001b[38;5;241m.\u001b[39madd(obj\u001b[38;5;241m.\u001b[39mndim)\n\u001b[1;32m    492\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ndims\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot concatenate object of type '<class 'numpy.ndarray'>'; only Series and DataFrame objs are valid"
     ]
    }
   ],
   "source": [
    "BATCHES = 1\n",
    "\n",
    "# Calculate batch size\n",
    "batch_size = len(data) // BATCHES + (len(data) % BATCHES > 0)\n",
    "\n",
    "# Initialize an empty list to store batch predictions\n",
    "covs = []\n",
    "\n",
    "# Predict in batches\n",
    "log.info(\"Predicting in batches...\")\n",
    "for i in trange(0, len(data), batch_size):\n",
    "    batch = data.iloc[i : i + batch_size]\n",
    "    batch_predictions = []\n",
    "\n",
    "    for submodel in cv_models_dir.iterdir():\n",
    "        if not submodel.stem.startswith(\"S1\"):\n",
    "            continue\n",
    "        log.info(\"Predicting with %s\", submodel.stem)\n",
    "        sub_predictor = joblib.load(str(submodel / \"model.pkl\"))\n",
    "        batch_predictions.append(sub_predictor.predict(batch))\n",
    "\n",
    "    log.info(\"Calculating coefficient of variation for batch %s...\", i)\n",
    "    # Calculate coefficient of variation across all submodel predictions\n",
    "    batch_cov = pd.concat(batch_predictions).std(axis=1) / pd.concat(\n",
    "        batch_predictions\n",
    "    ).mean(axis=1)\n",
    "    covs.append(batch_cov)\n",
    "\n",
    "# Concatenate all batch predictions\n",
    "full_cov = pd.concat(covs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_prediction_dfs = []\n",
    "for i, batch_prediction in enumerate(batch_predictions):\n",
    "    batch_prediction_dfs.append(pd.DataFrame(batch_prediction, columns=[f\"prediction_{i}\"]))\n",
    "\n",
    "full_predictions = pd.concat(batch_prediction_dfs, axis=1)\n",
    "cov = full_predictions.std(axis=1) / full_predictions.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            0.016514\n",
       "1            0.014311\n",
       "2            0.023106\n",
       "3            0.019038\n",
       "4            0.022063\n",
       "               ...   \n",
       "134187201    0.022066\n",
       "134187202    0.033093\n",
       "134187203    0.019086\n",
       "134187204    0.009998\n",
       "134187205    0.012896\n",
       "Length: 134187206, dtype: float32"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: #9 Plot CoV"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
